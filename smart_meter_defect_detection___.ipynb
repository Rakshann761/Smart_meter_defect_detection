{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ebCcGX0r8DS2"},"outputs":[],"source":["!pip install ultralytics\n","!pip install easyocr\n","!pip install opencv-python\n","\n","import os\n","import cv2\n","import math\n","import easyocr\n","from ultralytics import YOLO\n","from collections import Counter\n","import matplotlib.pyplot as plt\n","\n","!pip install -q streamlit opencv-python-headless easyocr matplotlib ultralytics\n","!npm install -g localtunnel\n","\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H3YC7odIbtNH","executionInfo":{"status":"ok","timestamp":1753870339586,"user_tz":-330,"elapsed":53107,"user":{"displayName":"1SI22CI044 RAKSHAN N","userId":"13201009937271383497"}},"outputId":"53c13ecf-be59-4dd3-c3f6-bf5dbda039cd"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["#Detection Model"],"metadata":{"id":"yyI2VM8hSDKB"}},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import easyocr\n","from ultralytics import YOLO\n","from collections import Counter\n","import matplotlib.pyplot as plt\n","\n","# --- Configuration ---\n","MODEL_PATHS = ['/content/drive/MyDrive/finalbest.pt']\n","SECONDARY_MODEL_PATH = '/content/drive/MyDrive/tele_sw_best.pt'\n","EARTH_MODEL_PATH = '/content/drive/MyDrive/best_earth.pt'\n","\n","REQUIRED_CLASSES = [\n","    'battery', 'bluethooth', 'clock', 'diode', 'dot', 'dwarrow', 'hazzard', 'magnet', 'redl',\n","    'ruppee', 'sdarrow', 'sym_T', 'tele', 'tempearature', 'uparrow',\n","    'bill', 'byp', 'cum', 'date', 'digit', 'kwarhz', 'last', 'md', 'mdm',\n","    'net', 'nmnd', 'pf', 'pp', 'rev', 'smdigit', 'switch', 'time', 'top', 'wifi', 'earth'\n","]\n","TEXT_CHECK_CLASSES = {\n","    'bill', 'byp', 'cum', 'date', 'last', 'md', 'mdm', 'net', 'nmnd',\n","    'pf', 'pp', 'rev', 'earth', 'time', 'top'\n","}\n","THIRD_STAGE_CLASSES = {'smdigit', 'tele', 'switch'}\n","\n","# --- Initialize models ---\n","reader = easyocr.Reader(['en'], gpu=True)\n","models = [YOLO(path) for path in MODEL_PATHS]\n","secondary_model = YOLO(SECONDARY_MODEL_PATH)\n","earth_model = YOLO(EARTH_MODEL_PATH)\n","\n","def read_and_preprocess_image(image_path):\n","    return cv2.imread(image_path)\n","\n","def save_crop(image, box, output_folder, class_name, index):\n","    x1, y1, x2, y2 = box\n","    if class_name == 'kwarhz':\n","        crop = image[y1-6:y2+10, x1-2:x2+2]\n","    else:\n","        crop = image[y1:y2, x1:x2]\n","    filename = os.path.join(output_folder, f\"{class_name}_{index}.png\")\n","    cv2.imwrite(filename, crop)\n","    return crop\n","\n","def run_detection(image):\n","    detections, detected_classes = [], []\n","    for model in models:\n","        results = model(image)\n","        for r in results:\n","            for box in r.boxes:\n","                cls_id = int(box.cls[0].item())\n","                class_name = model.names[cls_id]\n","                conf = box.conf[0].item()\n","                xyxy = list(map(int, box.xyxy[0].tolist()))\n","                detections.append({\n","                    'class': class_name,\n","                    'box': xyxy,\n","                    'conf': conf\n","                })\n","                detected_classes.append(class_name)\n","    return detections, detected_classes\n","\n","def custom_crop_for_ocr(image, box, cls, img_height, img_width):\n","    x1, y1, x2, y2 = box\n","    h, w = y2 - y1, x2 - x1\n","\n","    if cls in {'mdm', 'top'}:\n","        y2 +=16\n","        x1-=5\n","    elif cls == 'earth':\n","        y2 = y1 + int(h * 0.65)\n","\n","        x2 += 3\n","    elif cls == 'pp':\n","        x2 = min(x2 + 2, img_width)\n","    elif cls == 'rev':\n","        y2 = y1 + int(h * 0.65)\n","        x2 +=2\n","\n","    return image[y1:y2, x1:x2]\n","\n","def get_ocr_text(image_crop):\n","    gray = cv2.cvtColor(image_crop, cv2.COLOR_BGR2GRAY)\n","    result = reader.readtext(gray)\n","    return ''.join([res[1] for res in result]).replace(\"'\", \"\").replace(\" \", \"\").lower()\n","\n","def run_secondary_and_count(crop):\n","    results = secondary_model(crop)\n","    counts = Counter()\n","    for r in results:\n","        for box in r.boxes:\n","            class_idx = int(box.cls[0].item())\n","            name = secondary_model.names[class_idx]\n","            counts[name] += 1\n","    return counts\n","\n","def run_earth_model(crop):\n","    results = earth_model(crop)\n","    counts = Counter()\n","    for r in results:\n","        for box in r.boxes:\n","            class_idx = int(box.cls[0].item())\n","            name = earth_model.names[class_idx]\n","            counts[name] += 1\n","    return counts\n","\n","# ---- Main Function: run_defect_detection ----\n","def run_defect_detection(image_path, output_folder='crops'):\n","    if not os.path.exists(output_folder):\n","        os.makedirs(output_folder)\n","\n","    image = read_and_preprocess_image(image_path)\n","    height, width = image.shape[:2]\n","\n","    detections, detected_classes = run_detection(image)\n","\n","    for idx, det in enumerate(detections):\n","        det['crop'] = save_crop(image, det['box'], output_folder, det['class'], idx)\n","\n","    # --- Stage 1 ---\n","    counts = Counter(detected_classes)\n","    stage1_errors = []\n","    for cls in REQUIRED_CLASSES:\n","        count = counts.get(cls, 0)\n","        if cls == 'redl' and count != 2:\n","            stage1_errors.append(f\"Class '{cls}' has {count} detections (expected exactly 2)\")\n","        elif cls == 'digit' and count < 8:\n","            stage1_errors.append(f\"Class '{cls}' has {count} detections (expected at least 8)\")\n","        elif cls == 'dot' and count < 9:\n","            stage1_errors.append(f\"Class '{cls}' has {count} detections (expected at least 9)\")\n","        elif cls not in ['digit', 'dot', 'redl'] and count < 1:\n","            stage1_errors.append(f\"Class '{cls}' is missing\")\n","\n","    # --- Stage 2 ---\n","    stage2_errors = []\n","    ocr_by_class = {cls: [] for cls in TEXT_CHECK_CLASSES}\n","    for det in detections:\n","        cls = det['class']\n","        if cls in TEXT_CHECK_CLASSES:\n","            crop = custom_crop_for_ocr(image, det['box'], cls, height, width)\n","            text = get_ocr_text(crop)\n","            ocr_by_class[cls].append(text)\n","\n","\n","    for cls, texts in ocr_by_class.items():\n","      if not any(\n","          cls in t or\n","          (cls == 'top' and t in {'top', 't0p'}) or\n","          (cls == 'earth' and t in {'earth', 'eacth'})\n","          for t in texts\n","      ):\n","        stage2_errors.append(f\"OCR mismatch for class '{cls}': none matched, found {texts}\")\n","\n","    # --- Stage 3 ---\n","    stage3_errors = []\n","    for name, checks in {\n","        'smdigit': lambda c: c.get('smseg', 0) >= 14 and c.get('smdot', 0) >= 1,\n","        'tele': lambda c: c.get('tower', 0) >= 4,\n","        'switch': lambda c: all(c.get(k, 0) >= 1 for k in ['swl', 'swr', 'swb']),\n","    }.items():\n","        if any(d['class'] == name for d in detections):\n","            if not any(checks(run_secondary_and_count(d['crop'])) for d in detections if d['class'] == name):\n","                stage3_errors.append(f\"'{name}' failed: Missing Subclass\")\n","\n","    # --- Stage 4 ---\n","    stage4_errors = []\n","    for idx, det in enumerate(d for d in detections if d['class'] == 'digit'):\n","        gray = cv2.cvtColor(det['crop'], cv2.COLOR_BGR2GRAY)\n","        h, w = gray.shape\n","        seg_coords = {\n","            'A': (h//3 - 3, w - 7), 'B': (h//3*2 + 3, w - 7), 'C': (h - 4, w // 2),\n","            'D': (h//3*2 + 3, 7), 'E': (h//3 - 3, 7), 'F': (4, w // 2), 'G': (h // 2, w // 2)\n","        }\n","        failed = [s for s, (y, x) in seg_coords.items() if gray[y, x] > 120]\n","        if failed:\n","            stage4_errors.append(f\"Digit #{idx+1} segment check failed: segments {failed} have pixel > 120\")\n","\n","    # --- Stage 5 ---\n","    stage5_errors = []\n","    for det in detections:\n","        if det['class'] == 'kwarhz':\n","            crop = det['crop']\n","            h, w = crop.shape[:2]\n","            h = h//2\n","            w = w//2\n","            kw = crop[:, :math.ceil(w - w*0.09)]\n","            a = crop[:, math.ceil(w - w*0.255):]\n","            combined_text = (get_ocr_text(kw) + get_ocr_text(a)).lower()\n","            '''\n","            plt.subplot(1, 2, 1)\n","            plt.imshow(kw, cmap='gray')\n","            plt.axis('on')\n","            plt.title(\"KW Part\")\n","\n","            plt.subplot(1, 2, 2)\n","            plt.imshow(a, cmap='gray')\n","            plt.axis('on')\n","            plt.title(\"Arhz Part\")\n","            '''\n","            if 'kwarhz' not in combined_text:\n","                stage5_errors.append(f\"OCR mismatch for 'kwarhz': got '{combined_text}'\")\n","\n","    # --- Stage 6 ---\n","    stage6_errors = []\n","    earth_detections = [d for d in detections if d['class'] == 'earth']\n","    if earth_detections:\n","        if not any(run_earth_model(d['crop']).get('underline', 0) >= 3 for d in earth_detections):\n","            stage6_errors.append(\"'earth' defective: none of the earth crops had at least 3 underline detections\")\n","\n","    return {\n","        'stage1_errors': stage1_errors,\n","        'stage2_errors': stage2_errors,\n","        'stage3_errors': stage3_errors,\n","        'stage4_errors': stage4_errors,\n","        'stage5_errors': stage5_errors,\n","        'stage6_errors': stage6_errors\n","    }\n","\n","\n","if __name__ == \"__main__\":\n","    result = run_defect_detection(\"/content/test12.PNG\")\n","\n","    print(\"\\n--- Stage 1: Missing or Count Errors ---\")\n","    for err in result['stage1_errors']:\n","        print(err)\n","\n","    print(\"\\n--- Stage 2: OCR Mismatch Errors ---\")\n","    for err in result['stage2_errors']:\n","        print( err)\n","\n","    print(\"\\n--- Stage 3: Subclass Errors ---\")\n","    for err in result['stage3_errors']:\n","        print(err)\n","\n","    print(\"\\n--- Stage 4: 7-Segment digit Intensity Errors ---\")\n","    for err in result['stage4_errors']:\n","        print(err)\n","\n","    print(\"\\n--- Stage 5: KWARHZ OCR Errors ---\")\n","    for err in result['stage5_errors']:\n","        print(err)\n","\n","    print(\"\\n--- Stage 6: Earth Underline Detection Errors ---\")\n","    for err in result['stage6_errors']:\n","        print(err)\n"],"metadata":{"id":"KZttLP4h8y3r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753872917720,"user_tz":-330,"elapsed":5383,"user":{"displayName":"1SI22CI044 RAKSHAN N","userId":"13201009937271383497"}},"outputId":"86036b09-796b-4ff9-f268-4718e8d6ad19"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","0: 640x864 1 battery, 1 bill, 1 bluethooth, 1 byp, 1 clock, 1 cum, 1 date, 7 digits, 1 diode, 9 dots, 1 dwarrow, 1 earth, 1 hazzard, 1 kwarhz, 1 magnet, 1 md, 1 mdm, 1 net, 1 nmnd, 1 pf, 1 pp, 2 redls, 1 rev, 1 ruppee, 1 sdarrow, 4 smdigits, 1 switch, 1 sym_T, 1 tele, 1 tempearature, 1 time, 1 top, 1 uparrow, 1 wifi, 49.3ms\n","Speed: 5.3ms preprocess, 49.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 864)\n","\n","0: 800x864 14 smsegs, 70.2ms\n","Speed: 5.1ms preprocess, 70.2ms inference, 1.9ms postprocess per image at shape (1, 3, 800, 864)\n","\n","0: 864x736 10 smsegs, 68.6ms\n","Speed: 4.6ms preprocess, 68.6ms inference, 1.8ms postprocess per image at shape (1, 3, 864, 736)\n","\n","0: 864x544 5 smsegs, 69.6ms\n","Speed: 3.4ms preprocess, 69.6ms inference, 2.0ms postprocess per image at shape (1, 3, 864, 544)\n","\n","0: 864x448 5 smsegs, 70.3ms\n","Speed: 2.9ms preprocess, 70.3ms inference, 2.0ms postprocess per image at shape (1, 3, 864, 448)\n","\n","0: 864x864 4 towers, 38.1ms\n","Speed: 5.4ms preprocess, 38.1ms inference, 1.8ms postprocess per image at shape (1, 3, 864, 864)\n","\n","0: 640x864 2 swbs, 1 swl, 1 swr, 29.3ms\n","Speed: 3.7ms preprocess, 29.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 864)\n","\n","0: 672x864 9 underlines, 31.7ms\n","Speed: 4.5ms preprocess, 31.7ms inference, 1.9ms postprocess per image at shape (1, 3, 672, 864)\n","\n","--- Stage 1: Missing or Count Errors ---\n","Class 'digit' has 7 detections (expected at least 8)\n","Class 'last' is missing\n","\n","--- Stage 2: OCR Mismatch Errors ---\n","OCR mismatch for class 'last': none matched, found []\n","\n","--- Stage 3: Subclass Errors ---\n","'smdigit' failed: Missing Subclass\n","\n","--- Stage 4: 7-Segment digit Intensity Errors ---\n","\n","--- Stage 5: KWARHZ OCR Errors ---\n","\n","--- Stage 6: Earth Underline Detection Errors ---\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"0rq7JRn2cYj_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import shutil\n","import os\n","\n","folder_path = '/content/crops'\n","#folder_path = '/content/img'\n","\n","if os.path.exists(folder_path):\n","    shutil.rmtree(folder_path)\n","    print(f\" Deleted folder: {folder_path}\")\n","else:\n","    print(f\" Folder does not exist: {folder_path}\")"],"metadata":{"id":"hTa25uAacYgi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vmaQZsHbcYd3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OyOt6MUQU_6-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import cv2\n","import easyocr\n","from ultralytics import YOLO\n","from collections import Counter\n","import matplotlib.pyplot as plt\n","\n","# --- Configuration ---\n","model_paths = ['/content/drive/MyDrive/finalbest.pt']\n","secondary_model_path = '/content/drive/MyDrive/tele_sw_best.pt'\n","\n","required_classes = [\n","    'battery', 'bluethooth', 'clock', 'diode', 'dot', 'dwarrow', 'hazzard', 'magnet', 'redl',\n","    'ruppee', 'sdarrow', 'sym_T', 'tele', 'tempearature', 'uparrow',\n","    'bill', 'byp', 'cum', 'date', 'digit', 'kwarhz', 'last', 'md', 'mdm',\n","    'net', 'nmnd', 'pf', 'pp', 'rev', 'smdigit', 'switch', 'time', 'top', 'wifi', 'earth'\n","]\n","\n","text_check_classes = {\n","    'bill', 'byp', 'cum', 'date', 'last', 'md', 'mdm', 'net', 'nmnd',\n","    'pf', 'pp', 'rev', 'earth', 'time', 'top'\n","}\n","\n","third_stage_classes = {'smdigit', 'tele', 'switch'}\n","\n","reader = easyocr.Reader(['en'], gpu=True)\n","\n","# --- Load YOLO Models ---\n","models = [YOLO(path) for path in model_paths]\n","secondary_model = YOLO(secondary_model_path)\n","\n","def run_defect_detection(image_path, output_folder='crops'):\n","    if not os.path.exists(output_folder):\n","        os.makedirs(output_folder)\n","\n","    image = cv2.imread(image_path)\n","    height, width = image.shape[:2]\n","    detections = []\n","    detected_classes = []\n","\n","    for model in models:\n","        results = model(image)\n","        for r in results:\n","            for box in r.boxes:\n","                cls_id = int(box.cls[0].item())\n","\n","                class_name = model.names[cls_id]\n","                #print(class_name)\n","                conf = box.conf[0].item()\n","                xyxy = list(map(int, box.xyxy[0].tolist()))\n","                x1, y1, x2, y2 = xyxy\n","                if class_name == 'kwarhz':\n","\n","                  crop = image[y1-6:y2+10, x1-2:x2+2]\n","                  '''\n","                  plt.subplot(1, 2, 1)\n","                  plt.imshow(crop, cmap='gray')\n","                  plt.axis('on')\n","                  plt.title(\"KW Part\")\n","                  '''\n","                else:\n","                  crop = image[y1:y2, x1:x2]\n","                crop_filename = os.path.join(output_folder, f\"{class_name}_{len(detections)}.png\")\n","                cv2.imwrite(crop_filename, crop)\n","                detections.append({'class': class_name, 'box': [x1, y1, x2, y2], 'conf': conf,'crop':crop})\n","                detected_classes.append(class_name)\n","\n","    # --- Stage 1: Count validation ---\n","    counts = dict(Counter(detected_classes))\n","    class_counts = {cls: counts.get(cls, 0) for cls in required_classes}\n","    stage1_errors = []\n","\n","    for cls in required_classes:\n","        count = class_counts[cls]\n","        if cls == 'redl':\n","            if count != 2:\n","                stage1_errors.append(f\"Class '{cls}' has {count} detections (expected exactly 2)\")\n","        elif cls == 'digit':\n","            if count < 8:\n","                stage1_errors.append(f\"Class '{cls}' has {count} detections (expected at least 8)\")\n","        elif cls == 'dot':\n","            if count < 9:\n","                stage1_errors.append(f\"Class '{cls}' has {count} detections (expected at least 9)\")\n","        else:\n","            if count < 1:\n","                stage1_errors.append(f\"Class '{cls}' is missing\")\n","\n","    # --- Stage 2: OCR validation with class-specific cropping and matching ---\n","    stage2_errors = []\n","    img_height, img_width = image.shape[:2]\n","    class_ocr_texts = {cls: [] for cls in text_check_classes}\n","\n","    for det in detections:\n","        cls = det['class']\n","        if cls in text_check_classes:\n","            x1, y1, x2, y2 = det['box']\n","            h = y2 - y1\n","            w = x2 - x1\n","\n","            if cls in {'mdm', 'top'}:\n","                y2+=16\n","                x1-=5\n","                cropped = image[y1:y2, x1:x2]\n","\n","            elif cls == 'earth':\n","                y2_cropped = y1 + int(h * 0.65)\n","                x2+=3\n","                cropped = image[y1:y2, x1:x2]\n","\n","            elif cls == 'pp':\n","                x2_padded = min(x2 + 2, img_width)\n","                cropped = image[y1:y2, x1:x2_padded]\n","            elif cls == 'rev':\n","                y2_cropped = y1 + int(h * 0.5)\n","                x2+=2\n","                cropped = image[y1:y2_cropped, x1:x2]\n","            else:\n","                cropped = image[y1:y2, x1:x2]\n","\n","\n","\n","\n","            gray_crop = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)\n","            ocr_result = reader.readtext(gray_crop)\n","            text_cleaned = ''.join([res[1] for res in ocr_result]).lower()\n","            text_nospaces = ''.join(text_cleaned.replace(\"'\", \"\").split())\n","            class_ocr_texts[cls].append(text_nospaces)\n","\n","    for cls, texts in class_ocr_texts.items():\n","        match_found = False\n","        for text in texts:\n","\n","            if cls == 'top':\n","                if text in {'top', 't0p'} or cls in text :\n","                    match_found = True\n","                    break\n","            elif cls in text:\n","                match_found = True\n","                break\n","        if not match_found:\n","            stage2_errors.append(f\"OCR mismatch for class '{cls}': none matched, found {texts}\")\n","\n","    # --- Stage 3: Run third model on cropped smdigit, tele, switch ---\n","    stage3_errors = []\n","    third_stage_crops = [d for d in detections if d['class'] in third_stage_classes]\n","\n","\n","    stage4_errors = []\n","    digit_detections = [d for d in detections if d['class'] == 'digit']\n","\n","    for idx, det in enumerate(digit_detections):\n","        x1, y1, x2, y2 = det['box']\n","        crop = image[y1:y2, x1:x2]\n","        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n","        h, w = gray.shape[:2]\n","\n","        segment_coords = {\n","            'A': (h//3 - 3, w - 7),\n","            'B': (h//3*2 + 3, w - 7),\n","            'C': (h - 4, w // 2),\n","            'D': (h//3*2 + 3, 7),\n","            'E': (h//3 - 3, 7),\n","            'F': (4, w // 2),\n","            'G': (h // 2, w // 2),\n","        }\n","\n","        failed_segments = []\n","        for seg, (yy, xx) in segment_coords.items():\n","            if 0 <= yy < h and 0 <= xx < w:\n","                if gray[yy, xx] > 120:\n","                    failed_segments.append(seg)\n","\n","        if failed_segments:\n","            stage4_errors.append(\n","                f\"Digit #{idx+1} segment check failed: segments {failed_segments} have pixel > 100\"\n","            )\n","\n","    # --- Stage 3: Secondary Validation for smdigit, tele, switch ---\n","    stage3_errors = []\n","\n","    def run_secondary_and_count(crop):\n","        results = secondary_model(crop)\n","        counts = Counter()\n","        for r in results:\n","            for box in r.boxes:\n","                class_idx = int(box.cls[0].item())\n","                name = secondary_model.names[class_idx]\n","\n","                counts[name] += 1\n","        return counts\n","\n","    # --- smdigit ---\n","    smdigit_success = False\n","    for det in [d for d in detections if d['class'] == 'smdigit']:\n","        x1, y1, x2, y2 = det['box']\n","        crop = image[y1:y2+2, x1:x2+2]\n","        counts = run_secondary_and_count(crop)\n","\n","        if counts.get('smseg', 0) >= 14 and counts.get('smdot', 0) >= 1:\n","            smdigit_success = True\n","            break\n","\n","    if any(d['class'] == 'smdigit' for d in detections) and not smdigit_success:\n","        stage3_errors.append(\"'smdigit' failed: none of the crops had smsegs ≥ 14 and smdot ≥ 1\")\n","\n","    # --- tele ---\n","    tele_success = False\n","    for det in [d for d in detections if d['class'] == 'tele']:\n","        x1, y1, x2, y2 = det['box']\n","        crop = image[y1:y2+2, x1:x2+2]\n","        counts = run_secondary_and_count(crop)\n","\n","        if counts.get('tower', 0) >= 4:\n","            tele_success = True\n","            break\n","\n","    if any(d['class'] == 'tele' for d in detections) and not tele_success:\n","        stage3_errors.append(\"'tele' failed: none of the crops had towers ≥ 4\")\n","\n","    # --- switch ---\n","    switch_success = False\n","    for det in [d for d in detections if d['class'] == 'switch']:\n","        x1, y1, x2, y2 = det['box']\n","        crop = image[y1:y2+2, x1:x2+2]\n","        counts = run_secondary_and_count(crop)\n","\n","        if (counts.get('swl', 0) >= 1 and\n","            counts.get('swr', 0) >= 1 and\n","            counts.get('swb', 0) >= 1):\n","            switch_success = True\n","            break\n","\n","    if any(d['class'] == 'switch' for d in detections) and not switch_success:\n","        stage3_errors.append(\"'switch' failed: none of the crops had swl, swr, and swb ≥ 1\")\n","\n","    # --- Stage5 ---\n","    stage5_errors = []\n","    for det in detections:\n","        if det['class'] == 'kwarhz':\n","            crop = det['crop']\n","            h = crop.shape[0] // 2\n","            w = crop.shape[1] // 2\n","            kw = crop[:, :math.ceil(w - w*0.09)]\n","            a = crop[:, math.ceil(w - w*0.255):]\n","\n","            kw_gray = cv2.cvtColor(kw, cv2.COLOR_BGR2GRAY)\n","            a_gray = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n","\n","            kw_text = ''.join([res[1] for res in reader.readtext(kw_gray)]).replace(' ', '').lower()\n","            a_text = ''.join([res[1] for res in reader.readtext(a_gray)]).replace(' ', '').lower()\n","\n","            combined_text = (kw_text + a_text).replace(' ', '')\n","            if 'kwarhz' not in combined_text:\n","                stage5_errors.append(f\"OCR mismatch for 'kwarhz': got '{combined_text}'\")\n","\n","    # --- Stage 6: Earth underline detection using third model ---\n","    stage6_errors = []\n","    earth_model = YOLO('/content/drive/MyDrive/best_earth.pt')\n","    earth_detections = [d for d in detections if d['class'] == 'earth']\n","    earth_success = False\n","\n","    for det in earth_detections:\n","        x1, y1, x2, y2 = det['box']\n","        crop = image[y1:y2+2, x1:x2+2]\n","        results = earth_model(crop)\n","\n","        counts = Counter()\n","        for r in results:\n","            for box in r.boxes:\n","                class_idx = int(box.cls[0].item())\n","                name = earth_model.names[class_idx]\n","                counts[name] += 1\n","\n","        if counts.get('underline', 0) >= 3:\n","            earth_success = True\n","            break\n","\n","    if earth_detections and not earth_success:\n","        stage6_errors.append(\"'earth' failed: none of the crops had at least 3 underline detections\")\n","\n","    return {\n","        'stage1_errors': stage1_errors,\n","        'stage2_errors': stage2_errors,\n","        'stage3_errors': stage3_errors,\n","        'stage4_errors': stage4_errors,\n","        'stage5_errors': stage5_errors,\n","        'stage6_errors': stage6_errors\n","    }\n","\n","# --- Example usage ---\n","if __name__ == \"__main__\":\n","    result = run_defect_detection(\"/content/allgood_sharpened.png\")\n","\n","    print(\"\\n--- Stage 1: Missing or Count Errors ---\")\n","    for err in result['stage1_errors']:\n","        print( err)\n","\n","    print(\"\\n--- Stage 2: OCR Mismatch Errors ---\")\n","    for err in result['stage2_errors']:\n","        print( err)\n","\n","    print(\"\\n--- Stage 3: Model Output Errors ---\")\n","    for err in result['stage3_errors']:\n","        print(err)\n","\n","    print(\"\\n--- Stage 4: 7-Segment digit Intensity Errors ---\")\n","    for err in result['stage4_errors']:\n","        print( err)\n","\n","    print(\"\\n--- Stage 5: KWARHZ OCR Errors ---\")\n","    for err in result['stage5_errors']:\n","        print( err)\n","\n","    print(\"\\n--- Stage 6: Earth Underline Detection Errors ---\")\n","    for err in result['stage6_errors']:\n","        print(err)\n"],"metadata":{"id":"nEfgBXWRU_3_"},"execution_count":null,"outputs":[]}]}